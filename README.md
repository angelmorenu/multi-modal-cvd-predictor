# ğŸ©º Multi-Modal Predictors for Cardiovascular Disease Risk and Outcomes

**Author:** Angel Morenu  
**Email:** angel.morenu@ufl.edu  
**Affiliation:** University of Florida, M.S. in Applied Data Science  
**Course:** EEE 6778 â€“ Applied Machine Learning II (Fall 2025)  
**Instructor:** Dr. Ramirez-Salgado

---

## ğŸ§  Project Overview

Cardiovascular disease (CVD) remains the leading global cause of death. This project develops a multi-modal machine learning system that fuses:

- Tabular demographic data  
- Hospital admission records  
- Physiological 12â€‘lead ECG signals

The goal is improved CVD risk prediction with explainability and edge-deployable inference.

---

## ğŸ“¦ GitHub Repository

Repository: https://github.com/angelmorenu/multi-modal-cvd-predictor

Clone and navigate:
```bash
git clone https://github.com/angelmorenu/multi-modal-cvd-predictor.git
cd multi-modal-cvd-predictor
```

---

## ğŸ“Š Datasets Used

| Dataset | Description | Link |
|---|---:|---|
| Cardiovascular Diseases | Demographics and lifestyle features | https://www.kaggle.com/datasets/mexwell/cardiovascular-diseases |
| Hospital Admissions | Clinical visit and diagnostic records | https://www.kaggle.com/datasets/ashishsahani/hospital-admissions-data |
| PTB-XL ECG | 12-lead ECG signals and annotations | https://www.kaggle.com/datasets/khyeh0719/ptb-xl-dataset-reformatted |

---

## ğŸ—ï¸ Project Architecture

This hybrid workflow uses:
- scikit-learn for preprocessing and tabular baselines  
- PyTorch for ECG deep learning and feature fusion  
- Streamlit for the user interface  
- Conceptual Edge AI deployment (e.g., smartwatch scenario)

![Architecture Diagram](docs/multimodal_cvd_architecture.png)

---

## âš™ï¸ Installation and Environment Setup

Install with conda (choose the appropriate platform file):

```bash
# macOS (Intel or Apple Silicon M1/M2/M3; uses CPU/MPS)
conda env create -f environment.macos.yml
conda activate cvd_predictor

# Linux/Windows with NVIDIA GPU (CUDA 11.8)
conda env create -f environment.cuda.yml
conda activate cvd_predictor
```

Notes:
- On Apple Silicon, PyTorch uses the MPS backend when available.
- The default environment.yml is cross-platform (CPU/MPS-friendly).
- If conda dependency resolution is slow, install mamba:
```bash
conda install -c conda-forge mamba
```

---

## ğŸš€ Running the Project

1. Run the setup and EDA notebook:
```bash
jupyter notebook notebooks/setup.ipynb
```

2. Launch the Streamlit UI:
```bash
# Activate the conda environment
source /opt/anaconda3/etc/profile.d/conda.sh
conda activate cvd_predictor

# Run the Streamlit app
streamlit run ui/MultiModalCVD_app.py --server.port 8502 --server.headless true
```
This opens a local UI to input demographics, upload an ECG, and view predicted risk.

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8502
  Network URL: http://192.168.1.72:8502
  External URL: http://104.4.123.52:8502

---

## ğŸ“ Repository Structure

```
multi_modal_cvd_project/
â”œâ”€â”€ data/                     
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ setup.ipynb           
â”‚   â””â”€â”€ train_eval.ipynb      
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py         
â”‚   â”œâ”€â”€ model.py              
â”‚   â””â”€â”€ train.py, eval.py     
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                
â”‚   â””â”€â”€ MultiModalCVD_app.py  
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ plot_confusion.py   
|   â””â”€â”€ ui_demo.png  
â”‚ 
â”œâ”€â”€ figures
|   â””â”€â”€ confusion_matrix.png 
|   â””â”€â”€ ui_demo.png
â”‚   â””â”€â”€ multimodal_cvd_architecture.png
â”œâ”€â”€ results/                  
â”œâ”€â”€ environment.yml           
â”œâ”€â”€ environment.cuda.yml      
â”œâ”€â”€ environment.macos.yml     
â”œâ”€â”€ README.md                 
â”œâ”€â”€ Morenu_Project Deliverable 1.docx
â””â”€â”€ Morenu_Deliverable2_IEEE_Report.pdf
```

---

## ğŸ“¦ Deliverables

- Complete project repository (code + documentation)  
- Jupyter notebooks for setup and evaluation (setup.ipynb, train_eval.ipynb)  
- Streamlit application (ui/app.py and MultiModalCVD_app.py)  
- Technical IEEE report (Deliverable 2, PDF)  
- Environment YAML files for reproducibility

---

## âœ… Reproducibility Instructions

To reproduce Deliverable 2 results:

1. Run the evaluation notebook:
```bash
jupyter notebook notebooks/train_eval.ipynb
```
This trains/evaluates models and saves predictions to:
```bash
results/y_true.npy
results/y_pred.npy
results/y_prob.npy
```

2. Generate the confusion-matrix figure:
```bash
python scripts/plot_confusion.py
```
Output saved to:
```bash
figures/confusion_matrix.png
```

---

## ğŸ¤– Responsible AI Goals

- Fairness: Evaluate across age, gender, and race subgroups.  
- Transparency: Incorporate SHAP and saliency-based explanations.  
- Efficiency: Support lightweight edge deployment for on-device inference.  
- Reproducibility: Publish code, environment files, and metrics.

---

## ğŸ‘¤ Author & Contact

Angel Morenu  
University of Florida â€“ M.S. in Applied Data Science  
angel.morenu@ufl.edu  
GitHub: https://github.com/angelmorenu/multi-modal-cvd-predictor

This repository accompanies Deliverable 2 of EEE 6778 â€“ Applied Machine Learning II (Fall 2025).

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

% Font selection: choose fonts appropriate for your TeX engine (pdfLaTeX vs XeLaTeX/LuaLaTeX)
\usepackage{iftex}
\ifPDFTeX
    \usepackage[T1]{fontenc}
    \usepackage{newtxtext,newtxmath}
\else
    \usepackage{fontspec}
    \setmainfont{Times New Roman}
    \setsansfont{Arial}
    \setmonofont{Courier New}
    \usepackage{unicode-math}
    \setmathfont{TeX Gyre Termes Math}
\fi

% Core packages
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{amsmath,amssymb}
\usepackage[utf8]{inputenc} % safe fallback for pdfLaTeX
\usepackage{url}

% hyperref should be loaded last
\usepackage[hidelinks]{hyperref}

\title{Multi-Modal Predictors for Cardiovascular Disease Risk and Outcomes\\
Deliverable 2 -- Implementation and Early Evaluation}

\author{%
    \IEEEauthorblockN{Angel Morenu}
    \IEEEauthorblockA{M.S. Applied Data Science\\
    University of Florida\\
    EEE 6778 -- Applied Machine Learning II (Fall 2025)\\
    Instructor: Dr. Ramirez-Salgado\\
    Email: angel.morenu@ufl.edu}
}

\begin{document}

\maketitle

\begin{abstract}
Cardiovascular disease (CVD) remains the leading cause of death globally. This deliverable documents the implementation and early evaluation of a multi-modal predictive framework that fuses demographic (tabular), hospital admission (records), and physiological (ECG) data to estimate individual CVD risk. The prototype integrates a tabular encoder, a 1D-CNN ECG feature extractor, and a fusion classifier; training and evaluation scripts, a Streamlit interface, and reproducible preprocessing pipelines are included. Preliminary experiments demonstrate an end-to-end working system, provide baseline metrics, and identify key next steps for improving data scale, signal quality, model calibration, and interpretability.
\end{abstract}

\section{Project Summary}

\IEEEPARstart{C}{ardiovascular} disease (CVD) continues to be the leading cause of death worldwide and a major burden on health-care systems. Early detection of individual risk remains one of the most effective strategies for prevention, yet current predictive models often rely on narrow, single-source datasets such as demographic or clinical measurements alone. This limits their capacity to generalize to diverse populations and to capture subtle physiological indicators measurable through modern sensors.

This project aims to design, implement, and evaluate a multi-modal predictive framework that integrates heterogeneous data sources---demographic (tabular), hospital admission (records), and physiological (ECG signals)---to estimate CVD risk. The architecture blends traditional machine-learning methods with deep-learning models and exposes the resulting system through an interactive Streamlit interface suitable for clinical or educational demonstrations.

Since Deliverable 1, the project has transitioned from conceptual design to a functioning prototype. The preprocessing pipeline has been coded in scikit-learn, feature scaling and encoding have been standardized, and a PyTorch training loop has been implemented for the deep-learning components. The system can now train, evaluate, and generate predictions end-to-end. Early results, while modest, confirm that the pipeline executes reliably and provides a clear baseline for further optimization and interpretability research.

\section{System Architecture and Pipeline}

The implemented system follows a modular, data-to-inference workflow summarized in Figure~\ref{fig:architecture}. Each stage is independent yet integrated through shared data structures and consistent random-seed initialization to guarantee reproducibility.

\subsection{Data Ingestion and Preprocessing}
Raw data from three Kaggle datasets---(a) Cardiovascular Diseases \cite{cardio_ds}, (b) Hospital Admissions \cite{hospital_ds}, and (c) PTB-XL ECG Dataset \cite{ptbxl_ds}---are imported into the pipeline. Demographic and clinical variables are cleaned, missing values imputed, and categorical features encoded via one-hot encoding. Continuous features are scaled using StandardScaler. ECG signals, stored as NumPy arrays, are trimmed or zero-padded to a fixed length of 2\,000 samples and normalized to zero mean and unit variance.

\subsection{Feature Engineering and Alignment}
After cleaning, each modality is saved in standardized NumPy .npy format under data/processed/. Alignment scripts ensure that sample indices match across modalities so that a single observation corresponds to a single patient instance. Class imbalance is recorded, and stratified splits are produced for training, validation, and testing.

\subsection{Model Training}
Training is orchestrated by src/train.py. The script supports two regimes:
\begin{itemize}[leftmargin=*]
        \item Week 4 (ECG-only) -- a 1D CNN is trained on ECG inputs to validate architecture and convergence.
        \item Week 5 (Fusion) -- tabular embeddings and ECG features are concatenated and fed into a classification head.
\end{itemize}

The optimizer used is AdamW with learning rate $1\times10^{-3}$, batch size 64, and 10 epochs. Model checkpoints are stored in artifacts/. The architecture’s modularity permits future addition of text or imaging modalities.

\subsection{Evaluation and Metrics}
Evaluation is handled by src/eval.py, which loads the best checkpoint and computes Accuracy, ROC AUC, PR AUC, and Brier Score using scikit-learn. Confusion matrices and precision--recall plots are generated and saved in results/.

\subsection{Interface and Visualization}
The \texttt{Streamlit} front end connects the model to a browser-based user experience. Users can input numeric data or upload ECG files and instantly receive predictions with textual explanations. The interface is shown in Figure~\ref{fig:ui}.

\begin{figure}[!t]
\centering
\includegraphics[width=\linewidth]{architecture_v2.png}
\caption{System architecture.}
\label{fig:architecture}
\end{figure}

\section{Model Implementation Details}

The model leverages two complementary learning paradigms.

\subsection{Tabular Encoder}
Clinical and demographic attributes are fed into a fully connected network consisting of two linear layers with ReLU activation and dropout (0.3). This branch captures correlations among age, blood pressure, cholesterol, and lifestyle variables. The final hidden layer produces a dense 32-dimensional embedding.

\subsection{ECG Feature Extractor}
The ECG branch is implemented as a three-layer 1D CNN with kernel sizes (5, 5, 3) and stride 2, followed by batch normalization and ReLU non-linearities. The network outputs a 128-dimensional feature vector after global average pooling. This design balances representational power and computational efficiency, suitable for potential deployment on edge devices such as smartwatches.

\subsection{Fusion and Classification}
The tabular (32-D) and ECG (128-D) embeddings are concatenated into a 160-D fusion layer that feeds a fully connected classifier producing logits for two classes (CVD risk present/absent). A Softmax activation yields probabilities. Training uses cross-entropy loss; class weights can later be added to handle imbalance.

\subsection{Training Setup and Reproducibility}
Experiments were run on macOS Monterey using PyTorch’s MPS backend, 16 GB RAM, and 8-core CPU. Each run sets deterministic seeds across NumPy, Torch, and random. Checkpoints and logs include model state, optimizer state, and hyperparameters to facilitate resuming and auditability.

\subsection{Evaluation Metrics and Interpretation}
The metrics implemented correspond to three perspectives:
\begin{itemize}[leftmargin=*]
        \item Discrimination -- Accuracy and ROC AUC measure separability.
        \item Calibration -- Brier Score quantifies probabilistic reliability.
        \item Precision--Recall Trade-off -- PR AUC highlights sensitivity to rare positives.
\end{itemize}
Together they give a balanced assessment of early model behavior.

\section{Interface Prototype}

The graphical interface, implemented in \texttt{Streamlit}, transforms the research prototype into an accessible, interactive demonstration. Figure~\ref{fig:ui} illustrates the current layout.

Upon launch (\texttt{Streamlit run ui/MultiModalCVD\_app.py}), the interface loads the saved \texttt{artifacts/model.pt} and the preprocessing transformer. It presents sliders and dropdowns for demographic and clinical inputs (e.g., Age [20--90], Systolic BP, Cholesterol Category, Smoking Status) and a file uploader for ECG data.

Once users click Predict Risk, the app preprocesses inputs, feeds them through the model, and outputs a risk probability (0--1) with color-coded text:

\begin{itemize}[leftmargin=*]
        \item Low Risk ( < 0.33 ) -- green banner;
        \item Moderate Risk ( 0.33--0.66 ) -- orange;
        \item High Risk ( > 0.66 ) -- red alert.
\end{itemize}

The interface also plots the ECG waveform using Matplotlib and displays key statistics such as mean heart rate and signal length. All predictions are computed locally; no data is uploaded to remote servers, preserving privacy.

To ensure robustness, the application falls back to "demo mode" when no trained model is found---using random but deterministic predictions to keep the UI functional during testing.

\begin{figure}[!t]
\centering
\includegraphics[width=0.95\linewidth]{ui_screenshot.png}
\caption{Streamlit interface prototype.}
\label{fig:ui}
\end{figure}

\section{Early Evaluation and Results}

Preliminary experiments used small stratified splits of the Kaggle datasets to validate end-to-end execution rather than maximize accuracy. The model trained for 10 epochs showed consistent loss reduction and no catastrophic divergence, confirming that gradients propagate correctly through both branches.

\subsection{Training Logs}
Average training loss decreased from 0.68 to 0.59 over 10 epochs, and validation loss from 0.70 to 0.66. Validation accuracy rose from 0.50 to 0.70, demonstrating learning progress. Checkpoints were automatically saved when validation loss improved.

\subsection{Evaluation Results}
The test metrics obtained from eval.py are summarized in Table~I. Although overall accuracy (0.476) is low, the increasing validation trend and balanced loss curves indicate healthy training dynamics for a prototype model.

\begin{table}[htbp]
\centering
\caption{Preliminary Evaluation Metrics on Test Set}
\begin{tabular}{@{}lcc@{}}
\toprule
Metric & Value & Interpretation \\\midrule
Accuracy & 0.476 & Model learning baseline patterns \\
ROC AUC & 0.427 & Limited class separability \\
PR AUC & 0.539 & Moderate precision at low recall \\
Brier Score & 0.325 & Requires probability calibration \\\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:confusion} illustrates the confusion matrix. While the model currently overpredicts the positive class (11 false positives vs.\ 0 true negatives), it serves as a baseline for further data expansion and regularization.

Beyond numeric metrics, early qualitative tests show that the fusion approach produces smoother probability distributions than either modality alone, validating the multi-modal design choice.

\begin{figure}[!t]
\centering
\includegraphics[width=0.95\linewidth]{confusion_matrix.png}
\caption{Confusion matrix visualization.}
\label{fig:confusion}
\end{figure}

\section{Challenges and Next Steps}

\subsection{Data Limitations}
The most immediate challenge is data scale and balance. The cardiovascular datasets used are small samples extracted for demonstration purposes; the minority class (CVD positive) is underrepresented, leading to biased decision boundaries. To mitigate this, future work will implement weighted losses and SMOTE oversampling for tabular data.

\subsection{Signal Quality and Alignment}
ECG records exhibit variable sampling rates, missing leads, and noise spikes. Normalization and denoising filters (Butterworth band-pass and z-score) will be applied in subsequent iterations. Temporal alignment between ECG segments and clinical entries is also a priority for data integrity.

\subsection{Model Optimization}
Initial hyperparameters were conservative. Next steps include learning-rate scheduling, early stopping, and L2 regularization to prevent overfitting. Batch-size sensitivity will also be analyzed to balance gradient stability and training speed.

\subsection{Explainability and Transparency}
Deliverable 3 will emphasize interpretability. SHAP (Shapley Additive exPlanations) and Captum will be integrated to identify which features most influence model decisions. For ECG inputs, gradient saliency maps will highlight key signal regions associated with risk predictions. This addresses clinician trust and complements the Responsible AI objectives.

\subsection{Deployment Considerations}
Edge-AI deployment remains a long-term goal. The current PyTorch model will be quantized and exported to TorchScript for on-device inference. Latency and energy consumption will be benchmarked using a smartwatch-like environment.

\section{Responsible AI Reflection}

Responsible AI principles guide this project throughout its life cycle.

\subsection{Fairness}
The model will be evaluated on subgroups (age, gender, and ethnicity where available) to ensure equitable performance. Metrics such as equal opportunity and disparate impact will be added as the dataset grows.

\subsection{Transparency}
SHAP and attention-map visualizations provide traceable explanations for predictions. A model card will summarize architecture, training data, metrics, and limitations in plain language for non-experts.

\subsection{Privacy}
All data used are public and anonymized; the Streamlit app runs entirely locally without cloud storage. Future deployments will apply differential privacy and secure enclaves for edge computing contexts.

\subsection{Sustainability}
Training and inference were kept energy-efficient by using small batch sizes and lightweight architectures. A carbon-footprint estimate will be included in the final report per Green AI guidelines \cite{greenai}.

Together, these measures ensure that the system is not only technically sound but also aligned with ethical and societal expectations for AI in health care.

\section*{References}
\begin{thebibliography}{9}
\bibitem{scikit} Pedregosa et al., ``Scikit-learn: Machine Learning in Python,'' J. Mach. Learn. Res., vol. 12, pp. 2825--2830, 2011.
\bibitem{goodfellow} I. Goodfellow, Y. Bengio, and A. Courville, \textit{Deep Learning}. MIT Press, 2016.
\bibitem{raschka} S. Raschka, V. Mirjalili, and J. Hearty, \textit{Python Machine Learning}, 3rd ed., Packt, 2022.
\bibitem{cardio_ds} Kaggle, ``Cardiovascular Diseases Dataset,'' \url{https://www.kaggle.com/datasets/mexwell/cardiovascular-diseases}.
\bibitem{hospital_ds} Kaggle, ``Hospital Admissions Data,'' \url{https://www.kaggle.com/datasets/ashishsahani/hospital-admissions-data}.
\bibitem{ptbxl_ds} Kaggle, ``PTB-XL ECG Dataset (Reformatted),'' \url{https://www.kaggle.com/datasets/khyeh0719/ptb-xl-dataset-reformatted}.
\bibitem{greenai} R. Schwartz et al., ``Green AI,'' \textit{Commun. ACM}, vol. 63, no. 12, pp. 54--63, 2020.
\end{thebibliography}

\end{document}